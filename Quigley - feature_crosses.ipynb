{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_crosses.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL",
        "ZTDHHM61NPTw",
        "0i7vGo9PTaZl"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/joshquig/COMP840/blob/master/Quigley%20-%20feature_crosses.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "JndnmDMp66FL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "metadata": {
        "id": "hMqWDc_m6rUC",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g4T-_IsVbweU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Feature Crosses"
      ]
    },
    {
      "metadata": {
        "id": "F7dke6skIK-k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Learning Objectives:**\n",
        "  * Improve a linear regression model with the addition of additional synthetic features (this is a continuation of the previous exercise)\n",
        "  * Use an input function to convert pandas `DataFrame` objects to `Tensors` and invoke the input function in `fit()` and `predict()` operations\n",
        "  * Use the FTRL optimization algorithm for model training\n",
        "  * Create new synthetic features through one-hot encoding, binning, and feature crosses"
      ]
    },
    {
      "metadata": {
        "id": "NS_fcQRd8B97",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "4IdzD8IdIK-l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, as we've done in previous exercises, let's define the input and create the data-loading code."
      ]
    },
    {
      "metadata": {
        "id": "CsfdiLiDIK-n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
        "\n",
        "california_housing_dataframe = california_housing_dataframe.reindex(\n",
        "    np.random.permutation(california_housing_dataframe.index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "10rhoflKIK-s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_features(california_housing_dataframe):\n",
        "  \"\"\"Prepares input features from California housing data set.\n",
        "\n",
        "  Args:\n",
        "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
        "      from the California housing data set.\n",
        "  Returns:\n",
        "    A DataFrame that contains the features to be used for the model, including\n",
        "    synthetic features.\n",
        "  \"\"\"\n",
        "  selected_features = california_housing_dataframe[\n",
        "    [\"latitude\",\n",
        "     \"longitude\",\n",
        "     \"housing_median_age\",\n",
        "     \"total_rooms\",\n",
        "     \"total_bedrooms\",\n",
        "     \"population\",\n",
        "     \"households\",\n",
        "     \"median_income\"]]\n",
        "  processed_features = selected_features.copy()\n",
        "  # Create a synthetic feature.\n",
        "  processed_features[\"rooms_per_person\"] = (\n",
        "    california_housing_dataframe[\"total_rooms\"] /\n",
        "    california_housing_dataframe[\"population\"])\n",
        "  return processed_features\n",
        "\n",
        "def preprocess_targets(california_housing_dataframe):\n",
        "  \"\"\"Prepares target features (i.e., labels) from California housing data set.\n",
        "\n",
        "  Args:\n",
        "    california_housing_dataframe: A Pandas DataFrame expected to contain data\n",
        "      from the California housing data set.\n",
        "  Returns:\n",
        "    A DataFrame that contains the target feature.\n",
        "  \"\"\"\n",
        "  output_targets = pd.DataFrame()\n",
        "  # Scale the target to be in units of thousands of dollars.\n",
        "  output_targets[\"median_house_value\"] = (\n",
        "    california_housing_dataframe[\"median_house_value\"] / 1000.0)\n",
        "  return output_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ufplEkjN8KUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1205
        },
        "outputId": "bea266f3-8341-4790-a3f2-21dd7af5f5e1"
      },
      "cell_type": "code",
      "source": [
        "# Choose the first 12000 (out of 17000) examples for training.\n",
        "training_examples = preprocess_features(california_housing_dataframe.head(12000))\n",
        "training_targets = preprocess_targets(california_housing_dataframe.head(12000))\n",
        "\n",
        "# Choose the last 5000 (out of 17000) examples for validation.\n",
        "validation_examples = preprocess_features(california_housing_dataframe.tail(5000))\n",
        "validation_targets = preprocess_targets(california_housing_dataframe.tail(5000))\n",
        "\n",
        "# Double-check that we've done the right thing.\n",
        "print(\"Training examples summary:\")\n",
        "display.display(training_examples.describe())\n",
        "print(\"Validation examples summary:\")\n",
        "display.display(validation_examples.describe())\n",
        "\n",
        "print(\"Training targets summary:\")\n",
        "display.display(training_targets.describe())\n",
        "print(\"Validation targets summary:\")\n",
        "display.display(validation_targets.describe())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training examples summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       latitude  longitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "count   12000.0    12000.0             12000.0      12000.0         12000.0   \n",
              "mean       35.6     -119.6                28.4       2642.6           538.3   \n",
              "std         2.1        2.0                12.5       2168.6           418.2   \n",
              "min        32.5     -124.3                 1.0          8.0             1.0   \n",
              "25%        33.9     -121.8                18.0       1454.8           297.0   \n",
              "50%        34.2     -118.5                28.0       2127.5           432.0   \n",
              "75%        37.7     -118.0                37.0       3160.2           651.0   \n",
              "max        42.0     -114.3                52.0      32627.0          6445.0   \n",
              "\n",
              "       population  households  median_income  rooms_per_person  \n",
              "count     12000.0     12000.0        12000.0           12000.0  \n",
              "mean       1427.2       499.7            3.9               2.0  \n",
              "std        1152.9       380.0            1.9               1.3  \n",
              "min           3.0         1.0            0.5               0.1  \n",
              "25%         789.0       281.0            2.6               1.5  \n",
              "50%        1170.0       407.0            3.6               1.9  \n",
              "75%        1720.0       605.2            4.7               2.3  \n",
              "max       35682.0      6082.0           15.0              55.2  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>rooms_per_person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "      <td>12000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>35.6</td>\n",
              "      <td>-119.6</td>\n",
              "      <td>28.4</td>\n",
              "      <td>2642.6</td>\n",
              "      <td>538.3</td>\n",
              "      <td>1427.2</td>\n",
              "      <td>499.7</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>2168.6</td>\n",
              "      <td>418.2</td>\n",
              "      <td>1152.9</td>\n",
              "      <td>380.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>32.5</td>\n",
              "      <td>-124.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.9</td>\n",
              "      <td>-121.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1454.8</td>\n",
              "      <td>297.0</td>\n",
              "      <td>789.0</td>\n",
              "      <td>281.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>34.2</td>\n",
              "      <td>-118.5</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2127.5</td>\n",
              "      <td>432.0</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>407.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37.7</td>\n",
              "      <td>-118.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3160.2</td>\n",
              "      <td>651.0</td>\n",
              "      <td>1720.0</td>\n",
              "      <td>605.2</td>\n",
              "      <td>4.7</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>42.0</td>\n",
              "      <td>-114.3</td>\n",
              "      <td>52.0</td>\n",
              "      <td>32627.0</td>\n",
              "      <td>6445.0</td>\n",
              "      <td>35682.0</td>\n",
              "      <td>6082.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>55.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation examples summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       latitude  longitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "count    5000.0     5000.0              5000.0       5000.0          5000.0   \n",
              "mean       35.6     -119.6                28.9       2646.2           542.1   \n",
              "std         2.1        2.0                12.8       2207.1           429.4   \n",
              "min        32.6     -124.3                 1.0          2.0             2.0   \n",
              "25%        33.9     -121.8                18.0       1470.0           297.0   \n",
              "50%        34.2     -118.5                29.0       2126.5           437.0   \n",
              "75%        37.7     -118.0                38.0       3130.2           646.0   \n",
              "max        42.0     -114.6                52.0      37937.0          5471.0   \n",
              "\n",
              "       population  households  median_income  rooms_per_person  \n",
              "count      5000.0      5000.0         5000.0            5000.0  \n",
              "mean       1435.2       505.0            3.9               2.0  \n",
              "std        1135.7       395.1            1.9               0.8  \n",
              "min           6.0         2.0            0.5               0.0  \n",
              "25%         791.0       283.0            2.6               1.5  \n",
              "50%        1158.5       411.0            3.5               1.9  \n",
              "75%        1722.0       605.2            4.8               2.3  \n",
              "max       16122.0      5189.0           15.0              15.9  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>rooms_per_person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>35.6</td>\n",
              "      <td>-119.6</td>\n",
              "      <td>28.9</td>\n",
              "      <td>2646.2</td>\n",
              "      <td>542.1</td>\n",
              "      <td>1435.2</td>\n",
              "      <td>505.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.8</td>\n",
              "      <td>2207.1</td>\n",
              "      <td>429.4</td>\n",
              "      <td>1135.7</td>\n",
              "      <td>395.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>32.6</td>\n",
              "      <td>-124.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.9</td>\n",
              "      <td>-121.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1470.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>791.0</td>\n",
              "      <td>283.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>34.2</td>\n",
              "      <td>-118.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2126.5</td>\n",
              "      <td>437.0</td>\n",
              "      <td>1158.5</td>\n",
              "      <td>411.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37.7</td>\n",
              "      <td>-118.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>3130.2</td>\n",
              "      <td>646.0</td>\n",
              "      <td>1722.0</td>\n",
              "      <td>605.2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>42.0</td>\n",
              "      <td>-114.6</td>\n",
              "      <td>52.0</td>\n",
              "      <td>37937.0</td>\n",
              "      <td>5471.0</td>\n",
              "      <td>16122.0</td>\n",
              "      <td>5189.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training targets summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       median_house_value\n",
              "count             12000.0\n",
              "mean                206.1\n",
              "std                 115.4\n",
              "min                  15.0\n",
              "25%                 118.8\n",
              "50%                 178.9\n",
              "75%                 263.7\n",
              "max                 500.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>206.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>115.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>118.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>178.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>263.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation targets summary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       median_house_value\n",
              "count              5000.0\n",
              "mean                210.1\n",
              "std                 117.2\n",
              "min                  17.5\n",
              "25%                 121.4\n",
              "50%                 182.9\n",
              "75%                 267.6\n",
              "max                 500.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>210.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>117.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>17.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>121.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>182.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>267.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oJlrB4rJ_2Ma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns(input_features):\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Args:\n",
        "    input_features: The names of the numerical input features to use.\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\"\n",
        "  return set([tf.feature_column.numeric_column(my_feature)\n",
        "              for my_feature in input_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NBxoAfp2AcB6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
        "    \"\"\"Trains a linear regression model.\n",
        "  \n",
        "    Args:\n",
        "      features: pandas DataFrame of features\n",
        "      targets: pandas DataFrame of targets\n",
        "      batch_size: Size of batches to be passed to the model\n",
        "      shuffle: True or False. Whether to shuffle the data.\n",
        "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
        "    Returns:\n",
        "      Tuple of (features, labels) for next data batch\n",
        "    \"\"\"\n",
        "    \n",
        "    # Convert pandas data into a dict of np arrays.\n",
        "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
        " \n",
        "    # Construct a dataset, and configure batching/repeating.\n",
        "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    # Shuffle the data, if specified.\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    features, labels = ds.make_one_shot_iterator().get_next()\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hweDyy31LBsV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## FTRL Optimization Algorithm\n",
        "\n",
        "High dimensional linear models benefit from using a variant of gradient-based optimization called FTRL. This algorithm has the benefit of scaling the learning rate differently for different coefficients, which can be useful if some features rarely take non-zero values (it also is well suited to support L1 regularization). We can apply FTRL using the [FtrlOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/FtrlOptimizer)."
      ]
    },
    {
      "metadata": {
        "id": "S0SBf1X1IK_O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    feature_columns,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a linear regression model.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  as well as a plot of the training and validation loss over time.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    feature_columns: A `set` specifying the input feature columns to use.\n",
        "    training_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for training.\n",
        "    training_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for training.\n",
        "    validation_examples: A `DataFrame` containing one or more columns from\n",
        "      `california_housing_dataframe` to use as input features for validation.\n",
        "    validation_targets: A `DataFrame` containing exactly one column from\n",
        "      `california_housing_dataframe` to use as target for validation.\n",
        "      \n",
        "  Returns:\n",
        "    A `LinearRegressor` object trained on the training data.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "\n",
        "  # Create a linear regressor object.\n",
        "  my_optimizer = tf.train.FtrlOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  linear_regressor = tf.estimator.LinearRegressor(\n",
        "      feature_columns=feature_columns,\n",
        "      optimizer=my_optimizer\n",
        "  )\n",
        "  \n",
        "  training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                          training_targets[\"median_house_value\"], \n",
        "                                          batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                                  training_targets[\"median_house_value\"], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                    validation_targets[\"median_house_value\"], \n",
        "                                                    num_epochs=1, \n",
        "                                                    shuffle=False)\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"RMSE (on training data):\")\n",
        "  training_rmse = []\n",
        "  validation_rmse = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_regressor.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    # Take a break and compute predictions.\n",
        "    training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n",
        "    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
        "    validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
        "    \n",
        "    # Compute training and validation loss.\n",
        "    training_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(training_predictions, training_targets))\n",
        "    validation_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(validation_predictions, validation_targets))\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_rmse.append(training_root_mean_squared_error)\n",
        "    validation_rmse.append(validation_root_mean_squared_error)\n",
        "  print(\"Model training finished.\")\n",
        "\n",
        "  \n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_rmse, label=\"training\")\n",
        "  plt.plot(validation_rmse, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  return linear_regressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Cdr02tLIK_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "b188995a-1607-43fa-eca9-89622e19e771"
      },
      "cell_type": "code",
      "source": [
        "_ = train_model(\n",
        "    learning_rate=1.0,\n",
        "    steps=500,\n",
        "    batch_size=100,\n",
        "    feature_columns=construct_feature_columns(training_examples),\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "RMSE (on training data):\n",
            "  period 00 : 173.38\n",
            "  period 01 : 123.66\n",
            "  period 02 : 115.56\n",
            "  period 03 : 121.32\n",
            "  period 04 : 108.68\n",
            "  period 05 : 106.46\n",
            "  period 06 : 263.67\n",
            "  period 07 : 320.67\n",
            "  period 08 : 162.62\n",
            "  period 09 : 163.97\n",
            "Model training finished.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGACAYAAACz01iHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEnVUYERERCTqqMCIiIhI1Pn/qdv53EDVx6oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f70a9803790>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "i4lGvqajDWlw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One-Hot Encoding for Discrete Features\n",
        "\n",
        "Discrete (i.e. strings, enumerations, integers) features are usually converted into families of binary features before training a logistic regression model.\n",
        "\n",
        "For example, suppose we created a synthetic feature that can take any of the values `0`, `1` or `2`, and that we have a few training points:\n",
        "\n",
        "| # | feature_value |\n",
        "|---|---------------|\n",
        "| 0 |             2 |\n",
        "| 1 |             0 |\n",
        "| 2 |             1 |\n",
        "\n",
        "For each possible categorical value, we make a new **binary** feature of **real values** that can take one of just two possible values: 1.0 if the example has that value, and 0.0 if not. In the example above, the categorical feature would be converted into three features, and the training points now look like:\n",
        "\n",
        "| # | feature_value_0 | feature_value_1 | feature_value_2 |\n",
        "|---|-----------------|-----------------|-----------------|\n",
        "| 0 |             0.0 |             0.0 |             1.0 |\n",
        "| 1 |             1.0 |             0.0 |             0.0 |\n",
        "| 2 |             0.0 |             1.0 |             0.0 |"
      ]
    },
    {
      "metadata": {
        "id": "KnssXowblKm7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bucketized (Binned) Features\n",
        "\n",
        "Bucketization is also known as binning.\n",
        "\n",
        "We can bucketize `population` into the following 3 buckets (for instance):\n",
        "- `bucket_0` (`< 5000`): corresponding to less populated blocks\n",
        "- `bucket_1` (`5000 - 25000`): corresponding to mid populated blocks\n",
        "- `bucket_2` (`> 25000`): corresponding to highly populated blocks\n",
        "\n",
        "Given the preceding bucket definitions, the following `population` vector:\n",
        "\n",
        "    [[10001], [42004], [2500], [18000]]\n",
        "\n",
        "becomes the following bucketized feature vector:\n",
        "\n",
        "    [[1], [2], [0], [1]]\n",
        "\n",
        "The feature values are now the bucket indices. Note that these indices are considered to be discrete features. Typically, these will be further converted in one-hot representations as above, but this is done transparently.\n",
        "\n",
        "To define feature columns for bucketized features, instead of using `numeric_column`, we can use [`bucketized_column`](https://www.tensorflow.org/api_docs/python/tf/feature_column/bucketized_column), which takes a numeric column as input and transforms it to a bucketized feature using the bucket boundaries specified in the `boundardies` argument. The following code defines bucketized feature columns for `households` and `longitude`; the `get_quantile_based_boundaries` function calculates boundaries based on quantiles, so that each bucket contains an equal number of elements."
      ]
    },
    {
      "metadata": {
        "id": "cc9qZrtRy-ED",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_quantile_based_boundaries(feature_values, num_buckets):\n",
        "  boundaries = np.arange(1.0, num_buckets) / num_buckets\n",
        "  quantiles = feature_values.quantile(boundaries)\n",
        "  return [quantiles[q] for q in quantiles.keys()]\n",
        "\n",
        "# Divide households into 7 buckets.\n",
        "households = tf.feature_column.numeric_column(\"households\")\n",
        "bucketized_households = tf.feature_column.bucketized_column(\n",
        "  households, boundaries=get_quantile_based_boundaries(\n",
        "    california_housing_dataframe[\"households\"], 7))\n",
        "\n",
        "# Divide longitude into 10 buckets.\n",
        "longitude = tf.feature_column.numeric_column(\"longitude\")\n",
        "bucketized_longitude = tf.feature_column.bucketized_column(\n",
        "  longitude, boundaries=get_quantile_based_boundaries(\n",
        "    california_housing_dataframe[\"longitude\"], 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U-pQDAa0MeN3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 1: Train the Model on Bucketized Feature Columns\n",
        "**Bucketize all the real valued features in our example, train the model and see if the results improve.**\n",
        "\n",
        "In the preceding code block, two real valued columns (namely `households` and `longitude`) have been transformed into bucketized feature columns. Your task is to bucketize the rest of the columns, then run the code to train the model. There are various heuristics to find the range of the buckets. This exercise uses a quantile-based technique, which chooses the bucket boundaries in such a way that each bucket has the same number of examples."
      ]
    },
    {
      "metadata": {
        "id": "YFXV9lyMLedy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns():\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\" \n",
        "  households = tf.feature_column.numeric_column(\"households\")\n",
        "  longitude = tf.feature_column.numeric_column(\"longitude\")\n",
        "  latitude = tf.feature_column.numeric_column(\"latitude\")\n",
        "  housing_median_age = tf.feature_column.numeric_column(\"housing_median_age\")\n",
        "  median_income = tf.feature_column.numeric_column(\"median_income\")\n",
        "  rooms_per_person = tf.feature_column.numeric_column(\"rooms_per_person\")\n",
        "  \n",
        "  # Divide households into 7 buckets.\n",
        "  bucketized_households = tf.feature_column.bucketized_column(\n",
        "    households, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"households\"], 7))\n",
        "\n",
        "  # Divide longitude into 10 buckets.\n",
        "  bucketized_longitude = tf.feature_column.bucketized_column(\n",
        "    longitude, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"longitude\"], 10))\n",
        "\n",
        "  #\n",
        "  # YOUR CODE HERE: bucketize the following columns, following the example above:\n",
        "  #\n",
        "  bucketized_latitude = tf.feature_column.bucketized_column(\n",
        "    latitude, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"latitude\"], 10))\n",
        "  bucketized_housing_median_age = tf.feature_column.bucketized_column(\n",
        "    housing_median_age, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"housing_median_age\"], 5))\n",
        "  bucketized_median_income = tf.feature_column.bucketized_column(\n",
        "    median_income, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"median_income\"], 5))\n",
        "  bucketized_rooms_per_person = tf.feature_column.bucketized_column(\n",
        "    rooms_per_person, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"rooms_per_person\"], 5))\n",
        "  \n",
        "  feature_columns = set([\n",
        "    bucketized_longitude,\n",
        "    bucketized_latitude,\n",
        "    bucketized_housing_median_age,\n",
        "    bucketized_households,\n",
        "    bucketized_median_income,\n",
        "    bucketized_rooms_per_person])\n",
        "  \n",
        "  return feature_columns\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0FfUytOTNJhL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1221
        },
        "outputId": "456bb027-b3fa-4c99-a08d-620a6cfddb24"
      },
      "cell_type": "code",
      "source": [
        "_ = train_model(\n",
        "    learning_rate=1.0,\n",
        "    steps=500,\n",
        "    batch_size=100,\n",
        "    feature_columns=construct_feature_columns(),\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "RMSE (on training data):\n",
            "  period 00 : 168.18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1c1a5ae10d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtraining_targets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalidation_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     validation_targets=validation_targets)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-29885d35152f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(learning_rate, steps, batch_size, feature_columns, training_examples, training_targets, validation_examples, validation_targets)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Take a break and compute predictions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mtraining_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_training_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mtraining_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_predictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mvalidation_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_validation_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvalidation_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_predictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    559\u001b[0m             hooks=all_hooks) as mon_sess:\n\u001b[1;32m    560\u001b[0m           \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mpreds_evaluated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myield_single_examples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m               \u001b[0;32myield\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    581\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1057\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1060\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1205\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ZTDHHM61NPTw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below for a solution."
      ]
    },
    {
      "metadata": {
        "id": "JQHnUhL_NRwA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You may be wondering how to determine how many buckets to use. That is of course data-dependent. Here, we just selected arbitrary values so as to obtain a not-too-large model."
      ]
    },
    {
      "metadata": {
        "id": "Ro5civQ3Ngh_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns():\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\" \n",
        "  households = tf.feature_column.numeric_column(\"households\")\n",
        "  longitude = tf.feature_column.numeric_column(\"longitude\")\n",
        "  latitude = tf.feature_column.numeric_column(\"latitude\")\n",
        "  housing_median_age = tf.feature_column.numeric_column(\"housing_median_age\")\n",
        "  median_income = tf.feature_column.numeric_column(\"median_income\")\n",
        "  rooms_per_person = tf.feature_column.numeric_column(\"rooms_per_person\")\n",
        "  \n",
        "  # Divide households into 7 buckets.\n",
        "  bucketized_households = tf.feature_column.bucketized_column(\n",
        "    households, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"households\"], 7))\n",
        "\n",
        "  # Divide longitude into 10 buckets.\n",
        "  bucketized_longitude = tf.feature_column.bucketized_column(\n",
        "    longitude, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"longitude\"], 10))\n",
        "  \n",
        "  # Divide latitude into 10 buckets.\n",
        "  bucketized_latitude = tf.feature_column.bucketized_column(\n",
        "    latitude, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"latitude\"], 10))\n",
        "\n",
        "  # Divide housing_median_age into 7 buckets.\n",
        "  bucketized_housing_median_age = tf.feature_column.bucketized_column(\n",
        "    housing_median_age, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"housing_median_age\"], 7))\n",
        "  \n",
        "  # Divide median_income into 7 buckets.\n",
        "  bucketized_median_income = tf.feature_column.bucketized_column(\n",
        "    median_income, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"median_income\"], 7))\n",
        "  \n",
        "  # Divide rooms_per_person into 7 buckets.\n",
        "  bucketized_rooms_per_person = tf.feature_column.bucketized_column(\n",
        "    rooms_per_person, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"rooms_per_person\"], 7))\n",
        "  \n",
        "  feature_columns = set([\n",
        "    bucketized_longitude,\n",
        "    bucketized_latitude,\n",
        "    bucketized_housing_median_age,\n",
        "    bucketized_households,\n",
        "    bucketized_median_income,\n",
        "    bucketized_rooms_per_person])\n",
        "  \n",
        "  return feature_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RNgfYk6OO8Sy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_ = train_model(\n",
        "    learning_rate=1.0,\n",
        "    steps=500,\n",
        "    batch_size=100,\n",
        "    feature_columns=construct_feature_columns(),\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AFJ1qoZPlQcs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Crosses\n",
        "\n",
        "Crossing two (or more) features is a clever way to learn non-linear relations using a linear model. In our problem, if we just use the feature `latitude` for learning, the model might learn that city blocks at a particular latitude (or within a particular range of latitudes since we have bucketized it) are more likely to be expensive than others. Similarly for the feature `longitude`. However, if we cross `longitude` by `latitude`, the crossed feature represents a well defined city block. If the model learns that certain city blocks (within range of latitudes and longitudes) are more likely to be more expensive than others, it is a stronger signal than two features considered individually.\n",
        "\n",
        "Currently, the feature columns API only supports discrete features for crosses. To cross two continuous values, like `latitude` or `longitude`, we can bucketize them.\n",
        "\n",
        "If we cross the `latitude` and `longitude` features (supposing, for example, that `longitude` was bucketized into `2` buckets, while `latitude` has `3` buckets), we actually get six crossed binary features. Each of these features will get its own separate weight when we train the model."
      ]
    },
    {
      "metadata": {
        "id": "-Rk0c1oTYaVH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2: Train the Model Using Feature Crosses\n",
        "\n",
        "**Add a feature cross of `longitude` and `latitude` to your model, train it, and determine whether the results improve.**\n",
        "\n",
        "Refer to the TensorFlow API docs for [`crossed_column()`](https://www.tensorflow.org/api_docs/python/tf/feature_column/crossed_column) to build the feature column for your cross. Use a `hash_bucket_size` of `1000`."
      ]
    },
    {
      "metadata": {
        "id": "-eYiVEGeYhUi",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns():\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\" \n",
        "  households = tf.feature_column.numeric_column(\"households\")\n",
        "  longitude = tf.feature_column.numeric_column(\"longitude\")\n",
        "  latitude = tf.feature_column.numeric_column(\"latitude\")\n",
        "  housing_median_age = tf.feature_column.numeric_column(\"housing_median_age\")\n",
        "  median_income = tf.feature_column.numeric_column(\"median_income\")\n",
        "  rooms_per_person = tf.feature_column.numeric_column(\"rooms_per_person\")\n",
        "  \n",
        "  # Divide households into 7 buckets.\n",
        "  bucketized_households = tf.feature_column.bucketized_column(\n",
        "    households, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"households\"], 7))\n",
        "\n",
        "  # Divide longitude into 10 buckets.\n",
        "  bucketized_longitude = tf.feature_column.bucketized_column(\n",
        "    longitude, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"longitude\"], 10))\n",
        "  \n",
        "  # Divide latitude into 10 buckets.\n",
        "  bucketized_latitude = tf.feature_column.bucketized_column(\n",
        "    latitude, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"latitude\"], 10))\n",
        "\n",
        "  # Divide housing_median_age into 7 buckets.\n",
        "  bucketized_housing_median_age = tf.feature_column.bucketized_column(\n",
        "    housing_median_age, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"housing_median_age\"], 7))\n",
        "  \n",
        "  # Divide median_income into 7 buckets.\n",
        "  bucketized_median_income = tf.feature_column.bucketized_column(\n",
        "    median_income, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"median_income\"], 7))\n",
        "  \n",
        "  # Divide rooms_per_person into 7 buckets.\n",
        "  bucketized_rooms_per_person = tf.feature_column.bucketized_column(\n",
        "    rooms_per_person, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"rooms_per_person\"], 7))\n",
        "  \n",
        "  # YOUR CODE HERE: Make a feature column for the long_x_lat feature cross\n",
        "  long_x_lat = long_x_lat = tf.feature_column.crossed_column(\n",
        "  set([bucketized_longitude, bucketized_latitude]), hash_bucket_size=100)\n",
        "  \n",
        "  feature_columns = set([\n",
        "    bucketized_longitude,\n",
        "    bucketized_latitude,\n",
        "    bucketized_housing_median_age,\n",
        "    bucketized_households,\n",
        "    bucketized_median_income,\n",
        "    bucketized_rooms_per_person,\n",
        "    long_x_lat])\n",
        "  \n",
        "  return feature_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xZuZMp3EShkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1816
        },
        "outputId": "1fed4cb6-4d4d-4d65-f78e-f5df6c166d57"
      },
      "cell_type": "code",
      "source": [
        "_ = train_model(\n",
        "    learning_rate=1.0,\n",
        "    steps=500,\n",
        "    batch_size=100,\n",
        "    feature_columns=construct_feature_columns(),\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "RMSE (on training data):\n",
            "  period 00 : 161.86\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1c1a5ae10d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtraining_targets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalidation_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     validation_targets=validation_targets)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-29885d35152f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(learning_rate, steps, batch_size, feature_columns, training_examples, training_targets, validation_examples, validation_targets)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Take a break and compute predictions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mtraining_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_training_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mtraining_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_predictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mvalidation_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_validation_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvalidation_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_predictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    559\u001b[0m             hooks=all_hooks) as mon_sess:\n\u001b[1;32m    560\u001b[0m           \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mpreds_evaluated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myield_single_examples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m               \u001b[0;32myield\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    581\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1057\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1060\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1205\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0i7vGo9PTaZl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Solution\n",
        "\n",
        "Click below for the solution."
      ]
    },
    {
      "metadata": {
        "id": "3tAWu8qSTe2v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns():\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\" \n",
        "  households = tf.feature_column.numeric_column(\"households\")\n",
        "  longitude = tf.feature_column.numeric_column(\"longitude\")\n",
        "  latitude = tf.feature_column.numeric_column(\"latitude\")\n",
        "  housing_median_age = tf.feature_column.numeric_column(\"housing_median_age\")\n",
        "  median_income = tf.feature_column.numeric_column(\"median_income\")\n",
        "  rooms_per_person = tf.feature_column.numeric_column(\"rooms_per_person\")\n",
        "  \n",
        "  # Divide households into 7 buckets.\n",
        "  bucketized_households = tf.feature_column.bucketized_column(\n",
        "    households, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"households\"], 7))\n",
        "\n",
        "  # Divide longitude into 10 buckets.\n",
        "  bucketized_longitude = tf.feature_column.bucketized_column(\n",
        "    longitude, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"longitude\"], 10))\n",
        "  \n",
        "  # Divide latitude into 10 buckets.\n",
        "  bucketized_latitude = tf.feature_column.bucketized_column(\n",
        "    latitude, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"latitude\"], 10))\n",
        "\n",
        "  # Divide housing_median_age into 7 buckets.\n",
        "  bucketized_housing_median_age = tf.feature_column.bucketized_column(\n",
        "    housing_median_age, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"housing_median_age\"], 7))\n",
        "  \n",
        "  # Divide median_income into 7 buckets.\n",
        "  bucketized_median_income = tf.feature_column.bucketized_column(\n",
        "    median_income, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"median_income\"], 7))\n",
        "  \n",
        "  # Divide rooms_per_person into 7 buckets.\n",
        "  bucketized_rooms_per_person = tf.feature_column.bucketized_column(\n",
        "    rooms_per_person, boundaries=get_quantile_based_boundaries(\n",
        "      training_examples[\"rooms_per_person\"], 7))\n",
        "  \n",
        "  # YOUR CODE HERE: Make a feature column for the long_x_lat feature cross\n",
        "  long_x_lat = tf.feature_column.crossed_column(\n",
        "  set([bucketized_longitude, bucketized_latitude]), hash_bucket_size=1000) \n",
        "  \n",
        "  feature_columns = set([\n",
        "    bucketized_longitude,\n",
        "    bucketized_latitude,\n",
        "    bucketized_housing_median_age,\n",
        "    bucketized_households,\n",
        "    bucketized_median_income,\n",
        "    bucketized_rooms_per_person,\n",
        "    long_x_lat])\n",
        "  \n",
        "  return feature_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-_vvNYIyTtPC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_ = train_model(\n",
        "    learning_rate=1.0,\n",
        "    steps=500,\n",
        "    batch_size=100,\n",
        "    feature_columns=construct_feature_columns(),\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ymlHJ-vrhLZw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optional Challenge: Try Out More Synthetic Features\n",
        "\n",
        "So far, we've tried simple bucketized columns and feature crosses, but there are many more combinations that could potentially improve the results. For example, you could cross multiple columns. What happens if you vary the number of buckets? What other synthetic features can you think of? Do they improve the model?"
      ]
    }
  ]
}